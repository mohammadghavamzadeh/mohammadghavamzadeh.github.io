---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<br/> **PROFESSIONAL EXPERIENCE** <br/>

&nbsp;&nbsp; <span style="color:grey; font-size:0.875em;">**Senior Staff Research Scientist**</span> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp; <span style="color:grey; font-size:0.875em;">**Senior Research Scientist**</span> <br/>
&nbsp;&nbsp; <span style="font-size:0.85em;">Google Research  (Jun. 2020 - present)</span> &emsp;&emsp;&emsp;&emsp;&emsp;&nbsp; <span style="font-size:0.85em;">Facebook AI Research (FAIR)  (Oct. 2018 - Jun. 2020)</span>

&nbsp;&nbsp; <span style="color:grey; font-size:0.875em;">**Senior Staff Research Scientist**</span> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp; <span style="color:grey; font-size:0.875em;">**Senior Analytics Researcher**</span> <br/>
&nbsp;&nbsp; <span style="font-size:0.85em;">Google DeepMind  (Jun. 2017 - Oct. 2018)</span> &emsp;&emsp;&emsp;&emsp;&nbsp; <span style="font-size:0.85em;">Adobe Research  (Oct. 2013 - Jun. 2017)</span>

&nbsp;&nbsp; <span style="color:grey; font-size:0.875em;">**Chargé de Recherche  CR1**</span> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp; <span style="color:grey; font-size:0.875em;">**Chargé de recherche  CR2**</span> <br/>
&nbsp;&nbsp; <span style="font-size:0.85em;">INRIA Lille - Team SequeL  (2010 - Oct. 2013)</span> &emsp;&emsp;&emsp;&nbsp; <span style="font-size:0.85em;">INRIA Lille - Team SequeL  (2008 - 2010)</span>

&nbsp;&nbsp; <span style="color:grey; font-size:0.875em;">**Habilitation à Diriger des Recherches (HDR)**</span> &emsp;&emsp; <span style="color:grey; font-size:0.875em;">**Postdoctoral Fellow**</span> <br/>
&nbsp;&nbsp; <span style="font-size:0.85em;">Université Lille 1, France  (June 2014)</span> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp; <span style="font-size:0.85em;">University of Alberta, Canada  (2005 - 2008)</span>

&nbsp;&nbsp; <span style="color:grey; font-size:0.875em;">**Ph.D. in Computer Science**</span> <br/>
&nbsp;&nbsp; <span style="font-size:0.875em;">University of Massachusetts Amherst, USA  (2001 - 2005)</span>

<br/> **RESEARCH INTERESTS** &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; **EMAIL** <br/>
&emsp; <span style="color:grey; font-size:0.85em;">Machine Learning, Artificial Intelligence,</span>  &emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp; <span style="color:grey; font-size:0.85em;">ghavamza <span style="color:red">***at***</span> google <span style="color:red">***dot***</span> com</span> <br/>
&emsp; <span style="color:grey; font-size:0.85em;">Reinforcement Learning, Online Learning,</span>  &emsp;&emsp;&emsp;&emsp;&emsp; <span style="color:grey; font-size:0.85em;">mohammad <span style="color:red">***dot***</span> ghavamzadeh51 <span style="color:red">***at***</span> gmail <span style="color:red">***dot***</span> com</span> <br/>
&emsp; <span style="color:grey; font-size:0.85em;">Recommendation Systems, Control</span> 

### **RECENT NEWS ...**

### **2022**

- <span style="font-size:0.9em;">Four papers on <em>“Robust Reinforcement Learning using Offline Data”</em>, <em>“Operator Splitting Value Iteration”</em>, <em>“Efficient Risk-Averse Reinforcement Learning”</em>, and <em>“Private and Communication-Efficient Algorithms for Entropy Estimation”</em> got accepted at NeurIPS-2022.</span>

- <span style="font-size:0.9em;">I serve as an <em>area chair (senior meta-reviewer)</em> at AAAI-2023.</span>

- <span style="font-size:0.9em;">I serve as an <em>area chair</em> at ICLR-2023.</span>

- <span style="font-size:0.9em;">Two papers on <em>“Feature and Parameter Selection in Stochastic Linear Bandits”</em> and <em>“Deep Hierarchy in Bandits”</em> got accepted at ICML-2022.</span>

- <span style="font-size:0.9em;">A paper on <em>“Fixed-Budget Best-Arm Identification in Structured Bandits”</em> <span style="color:red">***got accepted for a long oral presentation (about %4 acceptance)***</span> at IJCAI-2022.</span>

- <span style="font-size:0.9em;">A paper on <em>“Multi-Environment Meta-Learning in Stochastic Linear Bandits”</em> got accepted at IEEE International Symposium on Information Theory (ISIT-2022).</span>

- <span style="font-size:0.9em;">A paper on <em>“Mirror Descent Policy Optimization”</em> got accepted at ICLR-2022.</span>

- <span style="font-size:0.9em;">A paper on <em>“Collaborative Multi-agent Stochastic Linear Bandits”</em> got accepted at ACC-2022.</span>

- <span style="font-size:0.9em;">Two papers on <em>“Thompson Sampling with a Mixture Prior”</em> and <em>“Hierarchical Bayesian Bandits”</em> got accepted at AISTATS-2022.</span>

- <span style="font-size:0.9em;">I was selected as a <em>highlighted area chair</em> at ICLR-2022.</span>

- <span style="font-size:0.9em;">I served as a <em>senior area chair</em> for NeurIPS-2022 and an <em>area chair</em> for ICLR-2022 and ICML-2022.</span>

- <span style="font-size:0.9em;">I serve as a guest editor for Machine Learning Journal (MLJ), Special Issue on Safe and Fair Machine Learning.</span>

### **2021**

- <span style="font-size:0.9em;">Two journal papers published: <em>“Active Learning for Classification with Abstention”</em> at IEEE Journal on Selected Areas in Information Theory (JSAIT), and <em>“A Review on Uncertainty Quantification in Deep Learning: Techniques, Applications, and Challenges”</em> at Elsevier Journal on Information Fusion.</span> 

- <span style="font-size:0.9em;">Seven conference papers published: <em>“Adaptive Sampling for Minimax Fair Classification”</em> at NeurIPS-2021, <em>“PID Accelerated Value Iteration Algorithm”</em> at ICML-2021, <em>“Variational Model-based Policy Optimization”</em> got accepted at IJCAI-2021, <em>“Neural Lyapunov Redesign”</em> at Learning for Dynamics & Control Conference (L4DC-2021), <em>“Stochastic Bandits with Linear Constraints”</em> at AISTATS-2021, <em>“Control-aware Representations for Model-based Reinforcement Learning”</em> at ICLR-2021, and <em>“Deep Bayesian Quadrature Policy Optimization”</em> at AAAI-2021.</span>

- <span style="font-size:0.9em;">I served as a <em>senior area chair</em> for NeurIPS-2021, and as an <em>area chair</em> for ICML-2021 and ICLR-2021.</span>

### **2020**

- <span style="font-size:0.9em;">Our paper on <em>“Active Learning for Classification with Abstention”</em> <span style="color:red">***short-listed as one of the six finalists for the Jack Keil Wolf  student paper award***</span> at IEEE International Symposium on Information Theory (ISIT-2020).</span>

- <span style="font-size:0.9em;">Our paper on <em>“Mirror Descent Policy Optimization”</em> <span style="color:red">***accepted for a contributed talk (8 out of about 250 submissions)***</span> at the Deep Reinforcement Learning Workshop at NeurIPS-2020.</span>

- <span style="font-size:0.9em;">Eleven conference papers published: <em>“Improved Algorithms for Conservative Exploration in Bandits”</em> at AAAI-2020, <em>“Prediction, Consistency, Curvature: Representation Learning for Locally-Linear Control”</em> at ICLR-2020, <em>“Randomized Exploration in Generalized Linear Bandits”</em> and <em>“Conservative Exploration in Reinforcement Learning”</em> at AISTATS-2020, <em>“Active Learning for Classification with Abstention”</em> at IEEE International Symposium on Information Theory (ISIT-2020), <em>“Adaptive Sampling for Estimating Probability Distributions”</em>, <em>“Multi-step Greedy Reinforcement Learning Algorithms”</em>, and <em>“Predictive Coding for Locally-Linear Control”</em> at ICML-2020, <em>“Active Model Estimation in Markov Decision Processes”</em> at UAI-2020, <em>“Safe Policy Learning for Continuous Control”</em> at CoRL-2020, and <em>“Online Planning with Lookahead Policies”</em> at NeurIPS-2020.</span> 

- <span style="font-size:0.9em;">I gave an invited talk on <em>“Conservative Exploration in Bandits and Reinforcement Learning”</em> at ICML workshop on <em>“Challenges in Deploying and Monitoring Machine Learning Systems”</em>, and an invited talk at the <em>“Reinforcement Learning Theory Session”</em> at INFORMS-2020.</span>   

- <span style="font-size:0.9em;">I co-chaired a tutorial on <em>“Exploration-Exploitation in Reinforcement Learning”</em> at AAAI-2020.</span>

- <span style="font-size:0.9em;">I served as a <em>senior area chair</em> for NeurIPS-2020, and as an <em>area chair</em> for ICML-2020 and AISTATS-2020.</span>

### **2019**

- <span style="font-size:0.9em;">Our paper on <em>“Tight Regret Bounds for Model-based Reinforcement Learning with Greedy Policies”</em> was accepted for <span style="color:red">***spotlight presentation***</span> at NeurIPS-2019.</span>

- <span style="font-size:0.9em;">Six conference papers published: <em>“Tight Regret Bounds for Model-based Reinforcement Learning with Greedy Policies”</em> at NeurIPS-2019, <em>“Perturbed-History Exploration in Stochastic Linear Bandits”</em> at UAI-2019, <em>“Perturbed-History Exploration in Stochastic Multi-Armed Bandits”</em> at IJCAI-2019, <em>“Garbage In, Reward Out: Bootstrapping Exploration in Multi-Armed Bandits”</em> at ICML-2019, and <em>“Risk-sensitive Generative Adversarial Imitation Learning”</em> and <em>“Optimizing over a Restricted Policy Class in MDPs”</em> at AISTATS-2019.</span>

- <span style="font-size:0.9em;">Our paper on <em>“Lyapunov-based Policy Optimization for Continuous Control”</em> <span style="color:red">***won the best paper award***</span> at ICML-2019 workshop on <em>“Reinforcement Learning in Real Life”</em>.</span>

- <span style="font-size:0.9em;">I co-chaired a workshop on <em>“Safety and Robustness in Decision-making”</em> at NeurIPS-2019.</span>

- <span style="font-size:0.9em;">I served as an <em>area chair</em> for ICML-2019 and NeurIPS-2019.</span>

### **2018**

- <span style="font-size:0.9em;">Two journal papers published: <em>“Proximal Gradient Temporal Difference Learning: Stable Reinforcement Learning with Polynomial Sample Complexity”</em> at Journal of Artificial Intelligence Research (JAIR), and <em>“Risk-Constrained Reinforcement Learning with Percentile Risk Criteria”</em> at Journal of Machine Learning Research (JMLR).</span>

- <span style="font-size:0.9em;">Six conference papers published: <em>“A Lyapunov-based Approach to Safe Reinforcement Learning”</em> and <em>“A Block Coordinate Ascent Algorithm for Mean-Variance Optimization”</em> at NIPS-2018, <em>“Path Consistency Learning in Tsallis Entropy Regularized MDPs”</em> and <em>“More Robust Doubly Robust Off-policy Evaluation”</em> at ICML-2018, <em>“Robust Locally-Linear Controllable Embedding”</em> at AISTATS-2018, and <em>“PAC Bandits with Risk Constraints”</em> at ISAIM-2018.</span> 

- <span style="font-size:0.9em;">I gave an invited talk on <em>“Three Approaches to Safety in Sequential Decision-making”</em> at ICML workshop on <em>“Machine Learning for Causal Inference, Counterfactual Prediction, and Autonomous Action"</em> (Causal ML).</span>

- <span style="font-size:0.9em;">I taught at the Deep Learning & Reinforcement Learning summer school organized by CIFAR and the Vector Institute at the University of Toronto in August.</span>

- <span style="font-size:0.9em;">I served as an <em>area chair</em> for NIPS-2018 and ICML-2018, and as a <em>senior program committee member</em> for IJCAI-2018 and AAAI-2018.</span>    

### **2017**

- <span style="font-size:0.9em;">A journal paper published: <em>“Sequential Decision-making with Coherent Risk”</em> at IEEE Transaction on Automatic Control (TAC).</span>

- <span style="font-size:0.9em;">Eight conference papers published: <em>“Conservative Contextual Linear Bandits”</em> at NIPS-2017, <em>“Active Learning for Accurate Estimation of Linear Models”</em>, <em>“Bottleneck Conditional Density Estimation”</em>, <em>“Diffusion Independent Semi-Bandit Influence Maximization”</em>, and <em>“Online Learning to Rank in Stochastic Click Models”</em> at ICML-2017, <em>“Sequential Multiple Hypothesis Testing with Type I Error Control”</em> at AISTATS-2017, <em>“Predictive Off-Policy Evaluation for Nonstationary Decision Problems”</em> and <em>“Automated Data Cleansing through Meta-Learning”</em> at IAAI-2017.</span>

- <span style="font-size:0.9em;">Together with Marek Petrik, we gave a tutorial on <em>“Risk-averse Decision-making and Control”</em> at AAAI-2017. [(tutorial website)](https://www.cs.unh.edu/~mpetrik/tutorials/risk)</span>    

- <span style="font-size:0.9em;">I gave an invited talk at the 2nd Asian Workshop on Reinforcement Learning in Seoul, South Korea on November 15, 2017.</span>

- <span style="font-size:0.9em;">I served as an <em>area chair</em> for NIPS-2017 and as a <em>senior program committee member</em> for AAAI-2017.</span> 

### **2016**

- <span style="font-size:0.9em;">Four journal papers published: <em>“Analysis of Classification-based Policy Iteration Algorithms”</em>, <em>“Bayesian Policy Gradient and Actor-Critic Algorithms”</em>, and <em>“Regularized Policy Iteration for Non-Parametric Function Spaces”</em> at Journal of Machine Learning Research (JMLR), and <em>“Variance-constrained Actor-Critic Algorithms for Discounted and Average Reward MDPs”</em> at Machine Learning Journal (MLJ).</span>

- <span style="font-size:0.9em;">Four conference papers published: <em>“Safe Policy Improvement by Minimizing Robust Baseline Regret”</em> at NIPS-2016, <em>“Improved Learning Complexity in Combinatorial Pure Exploration Bandits”</em> at AISTATS-2016, <em>“Proximal Gradient Temporal Difference Learning Algorithms”</em> at the sister conference best paper track at IJCAI-2016, and <em>“Graphical Model Sketch”</em> at ECML-2016.</span> 

- <span style="font-size:0.9em;">I gave an invited talk at the 13th European Workshop on Reinforcement Learning (EWRL) in Barcelona on December 3-4, 2016.</span>

- <span style="font-size:0.9em;">I served as a <em>senior program committee member</em> for IJCAI-2016 and ECML-2016.</span>

### **2015**

- <span style="font-size:0.9em;">Three journal papers published: <em>“Approximate Modified Policy Iteration and its Application to the Game of Tetris”</em> at Journal of Machine Learning Research (JMLR), <em>“Classification-based Approximate Policy Iteration”</em> at IEEE Transactions on Automatic Control (TAC), and <em>“Bayesian Reinforcement Learning: A Survey”</em> at Foundation and Trends in Machine Learning.</span> 

- <span style="font-size:0.9em;">Five conference papers published: <em>“High Confidence Off-Policy Evaluation”</em> at AAAI-2015, <em>“Maximum Entropy Semi-Supervised Inverse Reinforcement Learning”</em> at IJCAI-2015, <em>“Building Personalized Ad Recommendation Systems for Life-Time Value Optimization with Guarantees”</em> at IJCAI-2015, <em>“High Confidence Policy Improvement”</em> at ICML-2015, and <em>“Policy Gradient for Coherent Risk Measures”</em> at NIPS-2015.</span>

- <span style="font-size:0.9em;">Our paper entitled <em>“Finite-Sample Analysis of Proximal Gradient TD Algorithms”</em> won the <span style="color:red">***Facebook best student paper award***</span> at UAI-2015.</span> 

- <span style="font-size:0.9em;">I co-chaired two workshops: 12th European Workshop on Reinforcement Learning (EWRL-12) as a workshop at ICML-2015 and <em>“Machine Learning in eCommerce”</em> at NIPS-2015.</span>

- <span style="font-size:0.9em;">My student, Victor Gabillon, won the AFIA (French Association for Artificial Intelligence) prize for the 2nd best Ph.D. thesis (completed in 2014) on artificial intelligence in France.</span>

- <span style="font-size:0.9em;">I served as a <em>senior program committee member</em> for IJCAI-2015.</span> 

### **2014**

- <span style="font-size:0.9em;">A paper published: <em>“Algorithms for CVaR Optimization in MDPs”</em> at NIPS-2014.</span>

- <span style="font-size:0.9em;">I co-chaired three workshops: <em>“Sequential Decision-Making with Big Data”</em> at AAAI-2014, <em>“Customers Value Optimization in Digital Marketing”</em> at ICML-2014, and <em>“Large-scale Reinforcement Learning and Markov Decision Problems”</em> at NIPS-2014.</span>

- <span style="font-size:0.9em;">I successfully defended my <em>“Habilitation à Diriger des Recherches”</em> (HDR) thesis and graduated my Ph.D. student Victor Gabillon in June 2014. Victor will be a postdoc with Prof. Peter Bartlett at UC Berkeley starting October 2014.</span>

- <span style="font-size:0.9em;">I served as an <em>area chair</em> for NIPS-2014.</span>
